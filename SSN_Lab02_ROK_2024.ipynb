{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeTJ48dsJF332yAxNF9cN9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Sieci Neuronowe** (laboratorium 2/5)"],"metadata":{"id":"3-9gmqjN3PZd"}},{"cell_type":"markdown","source":["# **Cel**\n","\n","Celem laboratorium jest zrozumienie wpływu wybranych parametrów sieci neuronowej na uzyskany wynik. W tym celu wykorzystaj biblioteke **PyTorch** i dowolna bibliotekę pozwalająca na rysowanie wykresów.\n","\n","W sprawozdaniu odpowiedz na poniższe pytania opierając się o uzyskane wyniki w trakcie wykonywania eksperymentów:\n","\n","- Wykorzystaj stworzone tydzień temu modele dla dowolnego datasetu z poprzednich zajęć:\n","    - Wykorzystaj trzy [optymalizatory](https://pytorch.org/docs/stable/optim.html)\n","    - Podobnie zrób to z [funkcjami straty](https://pytorch.org/docs/stable/nn.html#loss-functions) tylko tym razem wybierz dwie.\n","    - I na podstawie dokumentacji przygotuj konfiguracje danego optymalizatora oraz funkcji straty.\n","    - Zmodyfikuj zmienną `batch size`. Zaproponuj 3 wartosci.\n","    - Skompiluj, wytrenuj i przetestuj model dla każdego parametru, wyniki zapisz w formie `Dataframe` w ktorych przedstawisz informacje o pramaetrach, osiągnięte `accuracy` i `loss`. Dodaj też informacje ile trwał proces uczenia (bibliteka `time`)\n","    - Przedstaw tabelkę posrotowaną względem `time`, `loss` oraz `acc`. Który zestaw parametrów okazał się najlepszy?\n","\n","\n","- Wykorzystaj jeszcze raz wybrany, inny model (`MNIST`, `CIFAR100`, `FashionMNIST`) które przygotowaliście w ramach poprzednich zajęć laboratoryjnych i przeprowadz proces hiperparametryzacje z wykorzystaniem `ParameterGrid` .**Pamiętaj że zajmie to więcej czasu!**. Wcześniej spróbuj wykorzystać 'Sequential` w celu przebudowania swojego modelu.\n","\n","- Dla każdego modelu narysuj przebieg `funkcji straty`, metryki `accuracy` oraz `f1-score`.\n","\n","- Jak wyniki porównaj z tym co udało się osiągnąć dla ręcznych poszukiwań. Jak oceniasz swoje wyniki? Czy człowiek ma szanse jeszce 'z palca' odnaleść najlepsze parametry dla sieci neuronowej czy jednak to już zadanie dla algorytmów optymalizacyjnych? Zaprezentuj wyniki przebiegu funkcji strat dla twojego modelu z dzis, modelu z poprzednich zajec oraz modelu z wykorzystniem `ParameterGrid`.\n","\n","\n","# **Dla ambitniejszych:**\n","To co wyzej, ale nie wykorzystuj modeli z poprzednich zajec, zaimplementuj 2 modele dla ponizyszch dwoch datasetow. Wykorzystaj `Sequential`. Potem ręcznie zmień parametry, a następnie wykorzystaj `ParameterGrid`. Finalnie w sposob tabelaryczny i z wykorzystaniem wykresów przedstaw analizę osiągniętych wyników. Pownienieś/Powinnaś porównać mimimum 5 modeli na 1 dataset.\n","\n","- Dataset: [Food101](https://pytorch.org/vision/stable/generated/torchvision.datasets.Food101.html#torchvision.datasets.Food101)\n","\n","```\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import Food101\n","\n","\n","# Używamy Food101 dataset z torchvision\n","train_data = Food101(root='food-101', split='train', transform=transform, download=True)\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","\n","test_data = Food101(root='food-101', split='test', transform=transform, download=True)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n","```\n","\n","- Dataset [Place365](https://pytorch.org/vision/stable/generated/torchvision.datasets.Places365.html#torchvision.datasets.Places365)\n","\n","```python\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import Places365\n","\n","# Przygotowanie danych\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","])\n","\n","# Używamy Places365 dataset z torchvision\n","train_data = Places365(root='places365', split='train-standard', download=True, transform=transform)\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","\n","test_data = Places365(root='places365', split='val', download=True, transform=transform)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n","\n","```"],"metadata":{"id":"c2m2v_oX3YQv"}},{"cell_type":"markdown","source":["1. **Kernel Size**: Jest to rozmiar okna konwolucji. W zależności od problemu, możesz wybrać różne rozmiary. Ogólnie rzecz biorąc, mniejsze jądra są bardziej skuteczne w wykrywaniu drobnych cech, podczas gdy większe jądra mogą pomóc w wykrywaniu cech o większej skali. Często stosowane rozmiary to (3x3) lub (5x5), ale to może się różnić w zależności od problemu.\n","\n","```python\n","\n","# Kernel Size: Rozmiar jądra konwolucyjnego\n","conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","\n","```\n","\n","2. **Max Pooling Size**: Max pooling służy do zmniejszania wymiarowości przestrzennej map cech. Popularne rozmiary to (2x2) lub (3x3). Max pooling pozwala zmniejszyć liczbę parametrów sieci.\n","\n","```python\n","# Max Pooling Size: Rozmiar okna max pooling\n","pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","```\n","\n","3. **Liczba cech (Feature Maps)**: Jest to liczba wyjściowych map cech po przejściu przez warstwy konwolucyjne. Możesz zacząć od mniejszej liczby map cech i stopniowo ją zwiększać w kolejnych warstwach, ale zawsze ważne jest unikanie zbytniego zwiększania liczby cech, co może prowadzić do nadmiernego dopasowania (overfitting).\n","\n","```python\n","# Liczba cech (Feature Maps): Liczba wyjściowych map cech\n","conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n","```\n","\n","4. **Stride**: Jest to liczba pikseli, o które przesuwa się okno konwolucji przy każdym kroku. Domyślnie jest to 1, ale można zwiększyć ten parametr, aby zmniejszyć wymiarowość mapy cech wyjściowej.\n","\n","```python\n","# Stride: Rozmiar kroku podczas konwolucji\n","conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\n","\n","```\n","\n","5. **Padding**: Pozwala na kontrolę rozmiaru wyjściowego mapy cech. 'Valid' oznacza brak dopełnienia (padding), co prowadzi do zmniejszenia rozmiaru mapy cech, a 'Same' oznacza dodanie dopełnienia w taki sposób, aby wyjściowa mapa miała ten sam rozmiar co wejściowa.\n","\n","```python\n","# Padding: Wartość dopełnienia\n","conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","```\n","Wartość padding=1 w warstwie **nn.Conv2d** w bibliotece PyTorch oznacza, że na wejściu do warstwy zostaną dodane 1 pikselowe ramki (zerowe wartości pikseli) na krawędziach obrazu, zarówno z góry i z dołu, jak i z prawej i z lewej strony. Ten rodzaj wypełnienia jest nazywany \"same\" padding. Dzięki temu, rozmiar wyjściowy obrazu po konwolucji będzie taki sam jak rozmiar obrazu wejściowego. Jeśli nie ma paddingu (padding=0), to obraz wejściowy jest traktowany jako \"brzegowy\", co oznacza, że rozmiar obrazu wyjściowego jest mniejszy niż obrazu wejściowego, ponieważ piksele brzegowe nie są rozszerzane.\n","\n","6. **Liczba warstw**: Możesz eksperymentować z różnymi głębokościami sieci. Jednak należy unikać zbyt dużych sieci, które mogą prowadzić do nadmiernego do\n","\n","Dobieranie tych parametrów często wymaga eksperymentów i dostosowania do konkretnego problemu. Możesz także korzystać z technik takich jak krzywe uczenia czy wizualizacje cech, aby lepiej zrozumieć działanie Twojej sieci i dostosować jej parametry.\n"],"metadata":{"id":"dwB3_8bmKzCt"}},{"cell_type":"markdown","source":["# Parametry procesu uczenia"],"metadata":{"id":"yDgOp7CYMDab"}},{"cell_type":"markdown","source":["# `batch size`\n","jest jednym z kluczowych hiperparametrów w uczeniu maszynowym, szczególnie podczas treningu modeli za pomocą metod gradientowych. Oznacza on liczbę przykładów danych, która jest przetwarzana w jednej iteracji podczas treningu. Wybór odpowiedniego batch size ma wpływ na szybkość uczenia, stabilność modelu oraz wykorzystanie zasobów obliczeniowych.\n","\n","Mała wartość `batch size` - może prowadzić do bardziej losowych aktualizacji wag modelu, co może przyspieszyć proces uczenia, ale może również sprawić, że proces ten będzie mniej stabilny.\n","\n","Duży `Batch Size`może przyspieszyć obliczenia, szczególnie na sprzętach z GPU, ale może prowadzić do mniejszej dokładności, ponieważ aktualizacje wag są mniej losowe.\n","\n","W PyTorch, batch size jest jednym z parametrów przekazywanych do DataLoadera podczas ładowania danych treningowych. DataLoader automatycznie dzieli zbiór danych na partie (batches) o określonym rozmiarze. Podczas iteracji po DataLoaderze, model przetwarza dane w batchach, a gradienty są obliczane na podstawie tych batchy.\n","\n","```python\n","from torch.utils.data import DataLoader\n","# Tworzenie DataLoadera z określonym batch size\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","```\n","\n","\n","\n","# `optymalizator` i jego parametry\n","\n","Optymalizator jest algorytmem używanym do aktualizacji wag modelu w trakcie treningu w celu minimalizacji funkcji straty. Istnieje wiele rodzajów optymalizatorów, takich jak SGD (Stochastic Gradient Descent), Adam, RMSprop, czy Adagrad. Każdy z tych optymalizatorów ma swoje własne parametry, które należy dostosować do konkretnego problemu i zestawu danych.\n","\n","- Learning Rate: Jest to jeden z najważniejszych parametrów optymalizatora, który określa krok aktualizacji wag w kierunku minimalizacji funkcji straty. Niewłaściwy learning rate może prowadzić do problemów z uczeniem się, takich jak zbyt wolne lub zbyt szybkie zmniejszanie funkcji straty.\n","\n","- Momentum: To parametr wprowadzony w niektórych optymalizatorach, który pomaga uniknąć zbyt szybkiego zatrzymywania się w lokalnych minimach poprzez akumulację poprzednich kroków aktualizacji wag.\n","\n","- Decay: Parametr ten kontroluje tempo zmniejszania się learning rate w trakcie treningu, co może pomóc w osiągnięciu lepszej konwergencji.\n","\n","Dobór optymalizatora i jego parametrów jest kwestią doświadczalną i wymaga przeprowadzenia odpowiednich eksperymentów w celu znalezienia najlepszej konfiguracji.\n","\n","# `Funkcja straty`\n","określa jak bardzo predykcje modelu różnią się od rzeczywistych etykiet (labeli) danych treningowych. Wybór odpowiedniej funkcji straty zależy od rodzaju problemu uczenia maszynowego, takiego jak klasyfikacja binarna, wieloklasowa, czy regresja.\n","\n","- Mean Squared Error (MSE): Jest często stosowaną funkcją straty w problemach regresji, gdzie chcemy minimalizować średnią kwadratową różnicę pomiędzy przewidywanymi a rzeczywistymi wartościami.\n","\n","- Cross-Entropy Loss: Jest powszechnie używana w problemach klasyfikacji, ponieważ penalizuje model za pewność swoich przewidywań. W przypadku klasyfikacji binarnej jest to Binary Cross-Entropy Loss, a w przypadku klasyfikacji wieloklasowej jest to Categorical Cross-Entropy Loss.\n","\n","Dobór odpowiedniej funkcji straty zależy od specyfiki problemu oraz typu danych, z którymi mamy do czynienia. W niektórych przypadkach istnieje również możliwość zdefiniowania niestandardowych funkcji straty, aby lepiej dopasować model do konkretnego zadania.\n","\n","W sumie, odpowiedni dobór batch size, optymalizatora i funkcji straty jest kluczowy dla skutecznego treningu modeli uczenia maszynowego. Wymaga to eksperymentowania i dostosowywania tych hiperparametrów w oparciu o charakterystykę danych oraz cel końcowy modelu."],"metadata":{"id":"DPBBOFXZH9OZ"}},{"cell_type":"markdown","source":["# Trochę technikali które mogą pomóc"],"metadata":{"id":"k5w69yk_BaRh"}},{"cell_type":"markdown","source":[],"metadata":{"id":"PmYSqQIYATSq"}},{"cell_type":"markdown","source":["`Sequential` w bibliotece PyTorch jest po prostu sekwencyjnym kontenerem modułów. Oznacza to, że umożliwia on definiowanie sekwencji warstw lub modułów, które zostaną wykonane jeden po drugim. Jest to przydatne, gdy chcemy zdefiniować prosty model, który składa się z sekwencji warstw, bez konieczności definiowania osobnej klasy dla każdej warstwy.\n","\n","W modelu Sequential moduły są przekazywane jako argumenty konstruktora w kolejności, w jakiej mają być wykonane. Każdy moduł musi mieć pojedynczy wejściowy i pojedynczy wyjściowy tensor, chyba że jest to pierwszy lub ostatni moduł w sekwencji, w którym wejście lub wyjście może mieć dowolny rozmiar.\n","\n","``` python\n","import torch\n","import torch.nn as nn\n","\n","# Definicja prostego modelu Sequential\n","model = nn.Sequential(\n","    nn.Linear(784, 128),  # Warstwa fully connected z 784 wejściami i 128 wyjściami\n","    nn.ReLU(),  # Funkcja aktywacji ReLU\n","    nn.Linear(128, 10)  # Druga warstwa fully connected z 128 wejściami i 10 wyjściami\n",")\n","\n","# Generowanie przykładowych danych wejściowych\n","input_data = torch.randn(64, 784)  # Losowe dane wejściowe dla 64 przykładów, każdy o rozmiarze 784 (28x28)\n","\n","# Przekazanie danych przez model\n","output = model(input_data)\n","\n","# Wyświetlenie kształtu wyjścia\n","print(\"Shape of output:\", output.shape)\n","\n","\n","```"],"metadata":{"id":"84ZiLGm_9La4"}},{"cell_type":"markdown","source":["Inny większy przykład:\n","\n","```python\n","def sequentialConv(in, out):\n","    # Funkcja convBlock tworzy blok konwolucyjny, który składa się z dwóch warstw konwolucyjnych, ReLU i BatchNormalization,\n","    # zakończonych warstwą MaxPooling.\n","    return nn.Sequential(\n","        nn.Conv2d(ni, no, kernel_size=3, padding=1),  # Pierwsza warstwa konwolucyjna, ni to liczba kanałów wejściowych, no to liczba kanałów wyjściowych\n","        nn.ReLU(inplace=True),  # Funkcja aktywacji ReLU\n","        nn.BatchNorm2d(no),  # Warstwa BatchNormalization\n","        nn.Conv2d(no, no, kernel_size=3, padding=1),  # Druga warstwa konwolucyjna, no to liczba kanałów wyjściowych\n","        nn.ReLU(inplace=True),  # Funkcja aktywacji ReLU\n","        nn.BatchNorm2d(no),  # Warstwa BatchNormalization\n","        nn.MaxPool2d(2),  # Warstwa MaxPooling\n","    )\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Inicjalizacja klasyfikatora, składającego się z pięciu bloków konwolucyjnych, adaptacyjnej warstwy AvgPool, warstw dropout oraz dwóch warstw fully connected.\n","        self.conv1 = sequentialConv(1, 32)  # Pierwszy blok konwolucyjny, wejście: 1 kanał (czarno-biały obraz), wyjście: 32 kanały\n","        self.conv2 = sequentialConv(32, 64)  # Drugi blok konwolucyjny, wejście: 32 kanały, wyjście: 64 kanały\n","        self.conv3 = sequentialConv(64, 128)  # Trzeci blok konwolucyjny, wejście: 64 kanały, wyjście: 128 kanałów\n","        self.conv4 = sequentialConv(128, 256)  # Czwarty blok konwolucyjny, wejście: 128 kanałów, wyjście: 256 kanałów\n","        self.conv5 = sequentialConv(256, 512)  # Piąty blok konwolucyjny, wejście: 256 kanałów, wyjście: 512 kanałów\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Warstwa adaptacyjnego AvgPool, zmniejsza rozmiar przestrzeni konwolucyjnej do (1, 1)\n","        self.dropout = nn.Dropout(0.5)  # Warstwa dropout z prawdopodobieństwem 0.5\n","        self.fc1 = nn.Linear(512, 256)  # Pierwsza warstwa fully connected, wejście: 512 cech, wyjście: 256 cech\n","        self.relu = nn.ReLU(inplace=True)  # Funkcja aktywacji ReLU\n","        self.fc2 = nn.Linear(256, 2)  # Druga warstwa fully connected, wejście: 256 cech, wyjście: 2 klasy\n","    \n","    def forward(self, x):\n","        # Przekazanie danych przez kolejne warstwy modelu\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)  # Spłaszczenie tensora do postaci wektora\n","        x = self.dropout(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x  # Zwrócenie wyników klasyfikacji\n","\n","```\n","\n"],"metadata":{"id":"tYN_GDDXA62f"}},{"cell_type":"markdown","source":["Żeby wykorzystac GPU potrzebne jest wykonanie operacji `to(device)`\n","\n","Wcześniej należy zdefiniować to urządzenie np.\n","`device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`\n","\n","a potem po stworzenie modelu należy uzupełnić o 'mapowanie' na ustalony `device`\n","`np. model = Net().to(device)`\n","\n","Trzeba pamiętać też o wykorzystaniu operacji `to(device)` w pętli uczącej:\n","\n","```python\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","    for images, labels in dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_correct += (predicted == labels).sum().item()\n","        total_samples += labels.size(0)\n","    accuracy = total_correct / total_samples\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {accuracy:.4f}\")\n","```\n"],"metadata":{"id":"ktgSncxnAnaw"}},{"cell_type":"markdown","source":["Zapis modelu do pliku `torch.save(model.state_dict(), \"model.pth\")`"],"metadata":{"id":"Hj2oR497AsMm"}},{"cell_type":"markdown","source":["# Hiperparametryzacja"],"metadata":{"id":"yqkS8YIpCb4E"}},{"cell_type":"markdown","source":["Przykladowy model sieci CNN dla klasyfikacji cyfr ze zbioru `MNIST`\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Definicja modelu CNN\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","def train_model(batch_size, learning_rate, num_epochs):\n","    model = CNN()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    for epoch in range(num_epochs):\n","        for i, (images, labels) in enumerate(train_loader):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","```\n"],"metadata":{"id":"NkmCSlfCCu8V"}},{"cell_type":"markdown","source":["**Hiperparametryzacja** odnosi się do procesu dostosowywania parametrów modelu, które nie są uczane podczas procesu trenowania, ale muszą być wybrane przed rozpoczęciem procesu uczenia. Parametry te wpływają na sposób, w jaki model jest uczony i jak zachowuje się podczas predykcji. Przykładowymi hiperparametrami mogą być współczynniki uczenia, liczba warstw w sieci neuronowej, rozmiar partii, liczba drzew w metodzie lasów losowych itp.\n","\n","W praktyce hiperparametryzacja polega na przeszukiwaniu przestrzeni hiperparametrów w celu znalezienia zestawu optymalnych wartości, które prowadzą do najlepszych wyników modelu.\n","\n","```python\n","from sklearn.model_selection import ParameterGrid\n","\n","# Przestrzeń hiperparametrów do przeszukania\n","# Tutaj można dodać więcej, np. funkcje straty, rodzaj optymalizatora itd.\n","param_grid = {\n","    'batch_size': [32, 64, 128],\n","    'learning_rate': [0.001, 0.01, 0.1],\n","    'num_epochs': [5, 10, 15]\n","}\n","\n","results = []\n","for params in ParameterGrid(param_grid):\n","    accuracy = train_model(params['batch_size'], params['learning_rate'], params['num_epochs'])\n","    results.append((params, accuracy))\n","\n","best_params, best_accuracy = max(results, key=lambda x: x[1])\n","print(\"Best parameters:\", best_params)\n","print(\"Best accuracy:\", best_accuracy)\n","\n","```\n","W tym przykładzie przeszukujemy przestrzeń hiperparametrów, a następnie oceniamy model dla każdej kombinacji hiperparametrów. Ostatecznie wybieramy zestaw, który osiągnął najwyższą dokładność na zestawie testowym."],"metadata":{"id":"_OlhsfIgDCBK"}}]}